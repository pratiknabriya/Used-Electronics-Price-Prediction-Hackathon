{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybbYn24Cs1Ec"
   },
   "source": [
    "# USED ELECTRONICS PRICE PREDICTION HACKATHON by MachineHack\n",
    "### Solution by: Pratik Nabriya |[ Github](https://github.com/pratiknabriya) | [LinkedIn](https://www.linkedin.com/in/pratiknabriya/) | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CvpGwyMhleum"
   },
   "source": [
    "### Description\n",
    "\n",
    "We live in a world that is driven by technology and electronic devices as gadgets have become a part of our daily life. It is near impossible to think of a world without smartphones or tablets. Like many kinds of goods or products, used electronic devices have a good demand in our country. In this hackathon, we challenge the data science community to predict the price of used electronic devices based on certain factors.\n",
    "\n",
    "Given are 6 distinguishing factors that can influence the price of a used device. Your objective as a data scientist is to build a machine learning model that can predict the price of used electronic devices based on the given factors.\n",
    "\n",
    "Data Description:-\n",
    "\n",
    "The unzipped folder will have the following files.\n",
    "\n",
    "Train.csv –  2326 observations.\n",
    "\n",
    "Test.csv –  997 observations.\n",
    "\n",
    "Target Variable: Price\n",
    "\n",
    "Evaluation:-\n",
    "\n",
    "The leaderboard is evaluated using RMSLE for the participant’s submission.\n",
    "\n",
    "For more info and data set visit: https://www.machinehack.com/course/used-electronics-price-prediction-weekend-hackathon-7/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9bg98nSvxIq"
   },
   "source": [
    "## Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "bDxiu25d41ru",
    "outputId": "8b7f9ae1-87fa-4103-914b-5ea388b8fa1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autocorrect\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/5b/6510d8370201fc96cbb773232c2362079389ed3285b0b1c6a297ef6eadc0/autocorrect-2.0.0.tar.gz (1.8MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 1.3MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
      "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for autocorrect: filename=autocorrect-2.0.0-cp36-none-any.whl size=1811641 sha256=2cdb95aad00dace91874207c3c04d2ece9e98513e5858a681755fdd978b2305b\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/06/bc/e66f28d72bed29591eadc79cebb2e7964ad0282804ab233da3\n",
      "Successfully built autocorrect\n",
      "Installing collected packages: autocorrect\n",
      "Successfully installed autocorrect-2.0.0\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries \n",
    "\n",
    "%matplotlib inline\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sqlite3 \n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "!pip install autocorrect\n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oT8xE1LI7SxG"
   },
   "outputs": [],
   "source": [
    "# mount google drive \n",
    "\n",
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCAyYxA6v5W9"
   },
   "source": [
    "## Load Data into Pandas DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJKsJIiv6uCF"
   },
   "outputs": [],
   "source": [
    "# reading data from google drive \n",
    "\n",
    "mypath = '/content/gdrive/My Drive/MachineHack/Used Electronics Price Prediction/'\n",
    "train_data = pd.read_csv(mypath + 'Train.csv')\n",
    "test_data = pd.read_csv(mypath + 'Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "iBj61E9W7Koj",
    "outputId": "d9c5ab78-a266-47cd-fca6-139e4d645de1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model_Info</th>\n",
       "      <th>Additional_Description</th>\n",
       "      <th>Locality</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>name0 name234 64gb space grey</td>\n",
       "      <td>1yesr old mobile number 999two905two99 bill c...</td>\n",
       "      <td>878</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>phone 7 name42 name453 new condition box acce...</td>\n",
       "      <td>101004800 1010065900 7000</td>\n",
       "      <td>1081</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>name0 x 256gb leess used good condition</td>\n",
       "      <td>1010010000 seperate screen guard 3 back cover...</td>\n",
       "      <td>495</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>name0 6s plus 64 gb space grey</td>\n",
       "      <td>without 1010020100 id 1010010300 colour 10100...</td>\n",
       "      <td>287</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>phone 7 sealed pack brand new factory outet p...</td>\n",
       "      <td>101008700 10100000 xs max 64 gb made 10100850...</td>\n",
       "      <td>342</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>26499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>name0 6 name1694 128gb clean condition</td>\n",
       "      <td>looks 1010035500 101008700 10100000 8 plus 64...</td>\n",
       "      <td>503</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>13800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>name87 watch name251 3 38 mm gps name119 name...</td>\n",
       "      <td>one 101009200 3 perfect working condition def...</td>\n",
       "      <td>940</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>17000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>name271 name1622 note 3gb ram 32gb inbuilt</td>\n",
       "      <td>10100000 6 101009200 16 gb good condition lig...</td>\n",
       "      <td>651</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>iphone 732gbcondition new</td>\n",
       "      <td>10100000 7 32gb 10100248300 condition unused ...</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>name0 7 128 gb</td>\n",
       "      <td>1010011400 101006100 101006200 available acce...</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand                                         Model_Info  ... State  Price\n",
       "0      1                      name0 name234 64gb space grey  ...     2  15000\n",
       "1      1   phone 7 name42 name453 new condition box acce...  ...     0  18800\n",
       "2      1            name0 x 256gb leess used good condition  ...     4  50000\n",
       "3      1                     name0 6s plus 64 gb space grey  ...     7  16500\n",
       "4      1   phone 7 sealed pack brand new factory outet p...  ...     0  26499\n",
       "5      1             name0 6 name1694 128gb clean condition  ...     5  13800\n",
       "6      1   name87 watch name251 3 38 mm gps name119 name...  ...     2  17000\n",
       "7      2         name271 name1622 note 3gb ram 32gb inbuilt  ...     6   5000\n",
       "8      1                          iphone 732gbcondition new  ...     6  21000\n",
       "9      1                                     name0 7 128 gb  ...     3  40000\n",
       "\n",
       "[10 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "ejezWt2u9nXt",
    "outputId": "6cc29f7e-1d8e-4381-b289-7119c266ccb4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model_Info</th>\n",
       "      <th>Additional_Description</th>\n",
       "      <th>Locality</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>name0 55s66s66s778xxsxsmax etc</td>\n",
       "      <td>good condition 11months old single scratch we...</td>\n",
       "      <td>570</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>slightly used excellent condition name0 5 sale</td>\n",
       "      <td>101008700 1010030600 1010034300 10100192200 1...</td>\n",
       "      <td>762</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>name0 sx ios12 top letast model bill call</td>\n",
       "      <td>1010017300 delivery</td>\n",
       "      <td>60</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>name87 name0 x 64gb going lowest 41900</td>\n",
       "      <td>phone 1010023400 64 gb excellent condition sale</td>\n",
       "      <td>640</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>name0 5s proper condition one handedly used</td>\n",
       "      <td>full kit available 10100248300 condition 4gb ...</td>\n",
       "      <td>816</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>name0 7 plus 128 gb name75 gold</td>\n",
       "      <td>101006600 galaxy advance hai ok ram 512 call</td>\n",
       "      <td>552</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>brand new rosegold name87 iphone name234 64gb...</td>\n",
       "      <td>office gurgaon karol bagh new 101008700 10100...</td>\n",
       "      <td>389</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>name0 se 32gb</td>\n",
       "      <td>101008700 iphone 4s new brand refurbished pac...</td>\n",
       "      <td>926</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>name0 6s name753</td>\n",
       "      <td>101006200 bill good battery backup good looking</td>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>apple phone 8 offer price</td>\n",
       "      <td>brand new 101006600 galaxy s10 plus box best ...</td>\n",
       "      <td>404</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand                                         Model_Info  ... City  State\n",
       "0      1                     name0 55s66s66s778xxsxsmax etc  ...   11      4\n",
       "1      1     slightly used excellent condition name0 5 sale  ...    8      2\n",
       "2      1          name0 sx ios12 top letast model bill call  ...   13      5\n",
       "3      1             name87 name0 x 64gb going lowest 41900  ...   15      5\n",
       "4      1        name0 5s proper condition one handedly used  ...    2      6\n",
       "5      1                    name0 7 plus 128 gb name75 gold  ...   13      5\n",
       "6      1   brand new rosegold name87 iphone name234 64gb...  ...    8      2\n",
       "7      1                                      name0 se 32gb  ...    8      2\n",
       "8      1                                   name0 6s name753  ...    2      6\n",
       "9      1                          apple phone 8 offer price  ...    2      6\n",
       "\n",
       "[10 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9Bte_t_19qMt",
    "outputId": "01159edd-b37e-4bb2-b0ab-f316d18b811c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2326, 7)\n",
      "(997, 6)\n"
     ]
    }
   ],
   "source": [
    "# shape of the data tables \n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKrw2cuQwEbC"
   },
   "source": [
    "## Check for Null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "ugi4gUt3-HZd",
    "outputId": "3c89a351-953f-43f7-bd98-a1ca549fbe37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brand                     0\n",
       "Model_Info                0\n",
       "Additional_Description    0\n",
       "Locality                  0\n",
       "City                      0\n",
       "State                     0\n",
       "Price                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "wDtTi1h--KuD",
    "outputId": "a1f8e0c4-297f-4654-f928-2c12d2b88cb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brand                     0\n",
       "Model_Info                0\n",
       "Additional_Description    0\n",
       "Locality                  0\n",
       "City                      0\n",
       "State                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38EswHp9AWVU"
   },
   "source": [
    "## Train-Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gEidlhkU-NtT",
    "outputId": "fb12ad5d-0dad-4b9f-f451-0284f112236d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 6) (1511,)\n",
      "(815, 6) (815,)\n",
      "(997, 6)\n"
     ]
    }
   ],
   "source": [
    "y_train = train_data['Price']\n",
    "X_train = train_data.drop('Price', axis = 1)\n",
    "X_test = test_data # a seperate test data is already provided \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size = 0.35, random_state = 42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_cv.shape, y_cv.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBQGEK5IwN6s"
   },
   "source": [
    "## Data cleaning and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "-e8cYMQPAvQc",
    "outputId": "c60abe03-f075-4706-a985-fe1b2ed4bece"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1353\n",
       "2      75\n",
       "0      58\n",
       "3      25\n",
       "Name: Brand, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "ydFSTXyPAySp",
    "outputId": "7fba47aa-b01b-4ec9-c904-bb7a6b3dcf08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193    34\n",
       "640    34\n",
       "534    24\n",
       "328    18\n",
       "132    17\n",
       "       ..\n",
       "706     1\n",
       "704     1\n",
       "703     1\n",
       "699     1\n",
       "568     1\n",
       "Name: Locality, Length: 753, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Locality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "fBcZDGVSA9s4",
    "outputId": "53b4bd75-6c76-4267-d269-eaaa0f30f9fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    213\n",
      "2     213\n",
      "8     176\n",
      "11    175\n",
      "0     169\n",
      "4     168\n",
      "13    136\n",
      "1     133\n",
      "10    108\n",
      "17     14\n",
      "12      4\n",
      "16      1\n",
      "7       1\n",
      "Name: City, dtype: int64\n",
      "(13,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train['City'].value_counts())\n",
    "print(X_train['City'].value_counts().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "yriZ2mOOBSzJ",
    "outputId": "084fe540-9fc9-4e31-a4ed-2feb4b78b5fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    349\n",
       "6    213\n",
       "2    176\n",
       "4    175\n",
       "1    170\n",
       "0    168\n",
       "3    133\n",
       "7    126\n",
       "8      1\n",
       "Name: State, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['State'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "do1HIxuuB4fK",
    "outputId": "5450f8f9-85c1-4313-9c92-4494ab2ceb66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " name87 name0 8 64gb black black name1588 name239\n",
      " name0 6 64gb\n",
      " name87 name0 excellent performance latest models name1202 name85 c\n",
      " name66 galaxy name108 30 name242 name243 11 months name114\n",
      " name87 name0 7 name92\n",
      " name0 10 256gb space gray pristine condition\n",
      " name87 iphone 6s 16 gb mint condition\n",
      " name0 6s 32 gigs storage\n",
      " name0 6 32gb pakka condition\n",
      " name87 8 64gb gold may 2020 warranty available\n",
      " name87 name0 8 name103 64gb\n",
      " name54 name120 name66 galaxy name578 1 year name114\n",
      " name54 2month pic name0 6s 32gb name1406 name61\n",
      " new box packed iphone name234 64gb brand new\n",
      " name0 x original new\n",
      " name87 iphone 7 plus 128gb\n",
      " used xs 64gb bought name734 bill\n",
      " phone 7plus 128gb\n",
      " name0 7 128gb\n"
     ]
    }
   ],
   "source": [
    "# check some random 'Model_info' rows\n",
    "\n",
    "for i in [1, 12, 45, 87, 123, 264, 387, 444, 545, 669, 729, 812, 901, 1021, 1103, 1234, 1231, 1422, 1500]:\n",
    "    print(X_train['Model_Info'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "09j3wJ9WxEHk"
   },
   "source": [
    "Some observations: \n",
    "\n",
    "name0 stands for iphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VpuKZPiHPNXN"
   },
   "outputs": [],
   "source": [
    "# function to correct spellings (english)\n",
    "def spell_check(sentence):\n",
    "  ''' This function is used to correct the words in the text'''\n",
    "  word_list = []\n",
    "  for word in sentence.strip().split():\n",
    "      word = spell(word) # correct each word in a sentence\n",
    "      word_list.append(word)\n",
    "        \n",
    "  return \" \".join(word_list) # return corrected sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MefgglLpE6Bj",
    "outputId": "608ecde9-cf62-46fd-f2b4-b9cf838baf2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1511/1511 [00:22<00:00, 66.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# applying spell corrector on the Model_Info feature \n",
    "spell = Speller(lang = 'en')\n",
    "\n",
    "preprocessed_model_info = []\n",
    "for sent in tqdm(X_train['Model_Info'].values):\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    sent = spell_check(sent)\n",
    "    preprocessed_model_info.append(sent.strip())\n",
    "\n",
    "X_train['preprocessed_model_info'] = preprocessed_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2q6uFxwNLcPV"
   },
   "outputs": [],
   "source": [
    "# as per our observation we replace the phone (iphone after spell correction becomes phone) with name \n",
    "X_train['preprocessed_model_info'] = X_train['preprocessed_model_info'].str.replace('phone', 'name0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "mp6TWTrCJd-j",
    "outputId": "cba813e7-76b8-433a-ba11-b5703ae8d704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name87 name0 8 64gb black black name1588 name239\n",
      "name0 6 64gb\n",
      "name87 name0 excellent performance latest models name1202 name85 c\n",
      "name66 galaxy name108 30 name242 name243 11 months name114\n",
      "name87 name0 7 name92\n",
      "name0 10 256gb space gray pristine condition\n",
      "name87 name0 6s 16 gb mint condition\n",
      "name0 6s 32 gigs storage\n",
      "name0 6 32gb pakka condition\n",
      "name87 8 64gb gold may 2020 warranty available\n",
      "name87 name0 8 name103 64gb\n",
      "name54 name120 name66 galaxy name578 1 year name114\n",
      "name54 2month pic name0 6s 32gb name1406 name61\n",
      "new box packed name0 name234 64gb brand new\n",
      "name0 x original new\n",
      "name87 name0 7 plus 128gb\n",
      "used xs 64gb bought name734 bill\n",
      "name0 7plus 128gb\n",
      "name0 7 128gb\n"
     ]
    }
   ],
   "source": [
    "# after above preprocessing steps - \n",
    "for i in [1, 12, 45, 87, 123, 264, 387, 444, 545, 669, 729, 812, 901, 1021, 1103, 1234, 1231, 1422, 1500]:\n",
    "    print(X_train['preprocessed_model_info'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mjUUhz3Jzh27",
    "outputId": "1f488221-93fe-4ec9-879f-005cdec48f61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [00:11<00:00, 69.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# apply above preprocessing on the validation and test datsets\n",
    "\n",
    "preprocessed_model_info = []\n",
    "\n",
    "for sent in tqdm(X_cv['Model_Info'].values):\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    sent = spell_check(sent)\n",
    "    preprocessed_model_info.append(sent.strip())\n",
    "\n",
    "X_cv['preprocessed_model_info'] = preprocessed_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8M4M2nPyzh3K"
   },
   "outputs": [],
   "source": [
    "X_cv['preprocessed_model_info'] = X_cv['preprocessed_model_info'].str.replace('phone', 'name0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kvomDoDWLyzw",
    "outputId": "462cb034-fc22-475f-e427-a5a9b6cc0441"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 997/997 [00:05<00:00, 169.28it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_model_info = []\n",
    "\n",
    "for sent in tqdm(X_test['Model_Info'].values):\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    sent = spell_check(sent)\n",
    "    preprocessed_model_info.append(sent.strip())\n",
    "\n",
    "X_test['preprocessed_model_info'] = preprocessed_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WuPvX3_hLy00"
   },
   "outputs": [],
   "source": [
    "X_test['preprocessed_model_info'] = X_test['preprocessed_model_info'].str.replace('phone', 'name0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "-L-NCrzNCLU3",
    "outputId": "e08f785c-3207-42f8-9c0b-f5e6594d87ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " looks brand new 101006800 10100179200 101006900 12gb ram 256gb 101001500 instant 1010010200 ur used 10100102300 please click see profile check devices 1010011300 available 1010095300 card accepted pavit 1010023900 17 10100157400 road opp nike showroom near karachi sweets woodland store camp pune 411001\n",
      " purchased 101004000 2018 1010099900 phone fantastic fabulous condition doesnt single scratch didnt even peel plastic thin cover phone back side till u observe 10100121400 101008900 101005100 101006100 charger clear view sensored flip cover avilable bargain n 1010011300 plz cause really know condition 101005100 10100171400 1010079100 101006600 sensored flipcover costs 3500 rupees 10100219100 till didnt even play single game note used professionally thank 10100200 10100200 reach 10100219200\n",
      " 10100000 6 16gb phone charger erd 100 condition 1010045600 sall\n",
      " perfect condition scratches\n",
      " 6gb 101004600 64gb memory 1010074600 101004200 2 months used excellent condition negotiable\n",
      " 10100000 10 256gb space gray box factory accessories mint condition always used case exchange giveaway marble case along phone worth 10000 rupees serious buyers contact price slightly negotiable\n",
      " 101006600 galaxy 1010031000 1010064500 runs 10100600 90 55inch qhd 2560x1440p pixel display latest variant mobile 101006600 galaxy 1010016600 phone powered 23 ghz octacore 1010013800 8890 processor 4gb ram galaxy 1010031000 1010064500 12 1010021200 primary camera 5 1010021200 frontfacing camera comes 128gb builtin storage expanded using microsd card 1010021500 includes dualsim 1010018700 1010032400 80211 abgnac 101009900 42 gps microusb 20 port device 3600 mah battery box charger battery back look like new\n",
      " iphones available 1010095300 1010037800 accepted 1010095300 1010037800 1010011500 available 1010062600 warranty pieces gb accessories bill box 600 iphones available 1010095300 1010037800 accepted 1010095300 1010037800 1010011500 available 1010062600 warranty pieces available prices fixed 1010095400 fb insta page olx profile 10100158800 1010023900 opposite 10100158900 10100159000 park 10100159100 10100158200 10100158600 10100159200 411042\n",
      " 10100000 xs 1010022900 64 gb box full kit\n",
      " 10100000 7 gold unboxed\n",
      " 101004200 4 gb 64 gb perfect condition\n",
      " 2 gb 16 gb\n",
      " dead phone\n",
      " scratch less black 16 gb\n",
      " 10gb ram 256 internal storage 100 condition\n",
      " 101005400 1010095000 2 box pack 1010015600 white 101008700 warranty 101005400 brand new box pack 1010011400 yes 1010010000 cover n toffen glass 1010011500 also available 1 1010095100 1010095200 2 1010095300 1010037800 call 1010095400 time 10am 10pm 100 fixed 1010017100 details 1010095500 message follow olx see daily new 1010095600 profile name 1010095700 mobi details call us direct call olx message 1010095500 contact 1010095800 1010083100 1010095700 mobi sg 9 2nd floorom complex opp mymy showroom 1010095900 roadcg roadahmedabad 1010025300 101003600 1010096000 1010096100\n",
      " perfect condition phone bought 14th 1010067700 box contents original bill\n",
      " rarely used box anaccessories available\n",
      " running condiotion original charger handsfree\n"
     ]
    }
   ],
   "source": [
    "# check some random samples of feature 'Additional_Description'\n",
    "\n",
    "for i in [1, 12, 45, 87, 123, 264, 387, 444, 545, 669, 729, 812, 901, 1021, 1103, 1234, 1231, 1422, 1500]:\n",
    "    print(X_train['Additional_Description'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v9sMA_TYCt_O",
    "outputId": "17d5464e-2151-4cc7-c731-5897e501ce6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1511/1511 [02:02<00:00, 12.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# apply the preprocessing steps on this feature just like the previous feature \n",
    "preprocessed_add_desc = []\n",
    "\n",
    "for sent in tqdm(X_train['Additional_Description'].values):\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    sent = \" \".join(filter(lambda x:x[:5]!='10100', sent.split())) # removes all encoded words starting with '10100'\n",
    "    sent = spell_check(sent)\n",
    "    preprocessed_add_desc.append(sent.strip())\n",
    "\n",
    "X_train['preprocessed_add_desc'] = preprocessed_add_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "PCzxivOUMeU_",
    "outputId": "e91ef15e-f8f2-45bc-bad8-639fe64c9888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looks brand new 12gb ram 256gb instant ur used please click see profile check devices available card accepted spavit 17 road opp nike showroom near karachi sweets woodland store camp pure 411001\n",
      "purchased 2018 phone fantastic fabulous condition doesnt single scratch didnt even peel plastic thin cover phone back side till u observe charger clear view censored flip cover available bargain n ply cause really know condition censored slipcover costs 3500 rupees till didnt even play single game note used professionally thank reach\n",
      "6 16gb phone charger erd 100 condition sall\n",
      "perfect condition scratches\n",
      "6gb 64gb memory 2 months used excellent condition negotiable\n",
      "10 256gb space gray box factory accessories mint condition always used case exchange giveaway marble case along phone worth 10000 rupees serious buyers contact price slightly negotiable\n",
      "galaxy runs 90 55inch thd 2560x1440p pixel display latest variant mobile galaxy phone powered 23 ghz outscore 8890 processor 4gb ram galaxy 12 primary camera 5 frontfacing camera comes 128gb builtin storage expanded using micros card includes dualism 80211 cognac 42 gps microtus 20 port device 3600 may battery box charger battery back look like new\n",
      "phones available accepted available warranty pieces gb accessories bill box 600 phones available accepted available warranty pieces available prices fixed fb inst page old profile opposite park 411042\n",
      "xs 64 gb box full kit\n",
      "7 gold unboxed\n",
      "4 gb 64 gb perfect condition\n",
      "2 gb 16 gb\n",
      "dead phone\n",
      "scratch less black 16 gb\n",
      "10gb ram 256 internal storage 100 condition\n",
      "2 box pack white warranty brand new box pack yes cover n toffee glass also available 1 2 call time 10am 10pm 100 fixed details message follow old see daily new profile name mob details call us direct call old message contact mob sg 9 2nd floor complex opp mym showroom road roadahmedabad\n",
      "perfect condition phone bought 14th box contents original bill\n",
      "rarely used box nonaccessories available\n",
      "running condition original charger handsfree\n"
     ]
    }
   ],
   "source": [
    "# after preprocessing \n",
    "for i in [1, 12, 45, 87, 123, 264, 387, 444, 545, 669, 729, 812, 901, 1021, 1103, 1234, 1231, 1422, 1500]:\n",
    "    print(X_train['preprocessed_add_desc'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vfqfb4kbVbub",
    "outputId": "2e1dd89b-3b53-4755-84e8-55e0c347b07b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [00:57<00:00, 14.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# apply above preprocessing steps to additional_description in cv and test dataset as well\n",
    "\n",
    "preprocessed_add_desc = []\n",
    "\n",
    "for sent in tqdm(X_cv['Additional_Description'].values):\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    sent = \" \".join(filter(lambda x:x[:5]!='10100', sent.split()))\n",
    "    sent = spell_check(sent)\n",
    "    preprocessed_add_desc.append(sent.strip())\n",
    "\n",
    "X_cv['preprocessed_add_desc'] = preprocessed_add_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HkFUnS1Yz_rm",
    "outputId": "bf33205d-b7af-49d4-c210-399ef3dfc44f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 997/997 [00:58<00:00, 16.92it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_add_desc = []\n",
    "\n",
    "for sent in tqdm(X_test['Additional_Description'].values):\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    sent = \" \".join(filter(lambda x:x[:5]!='10100', sent.split()))\n",
    "    sent = spell_check(sent)\n",
    "    preprocessed_add_desc.append(sent.strip())\n",
    "\n",
    "X_test['preprocessed_add_desc'] = preprocessed_add_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "neKX_2XH2eg4"
   },
   "source": [
    "## Text Feature encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0nNsq-3V6NY"
   },
   "source": [
    "#### One hot encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "k-oOmb9kV-H5",
    "outputId": "b3a0f07e-ed76-47eb-d1fd-31473730f742"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Brand', 'Model_Info', 'Additional_Description', 'Locality', 'City',\n",
       "       'State', 'preprocessed_model_info', 'preprocessed_add_desc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "qxMenXm1WAHn",
    "outputId": "2f3197e0-a66d-4705-c1f6-0bd796a86716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After encoding\n",
      "(1511, 4) (1511,)\n",
      "(815, 4) (815,)\n",
      "(997, 4)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding 'Brand'\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(X_train['Brand'].values.reshape(-1, 1))\n",
    "\n",
    "X_train_brand = encoder.transform(X_train['Brand'].values.reshape(-1, 1))\n",
    "X_cv_brand = encoder.transform(X_cv['Brand'].values.reshape(-1, 1))\n",
    "X_test_brand = encoder.transform(X_test['Brand'].values.reshape(-1, 1))\n",
    "\n",
    "print(\"After encoding\")\n",
    "print(X_train_brand.shape, y_train.shape)\n",
    "print(X_cv_brand.shape, y_cv.shape)\n",
    "print(X_test_brand.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "yYPPTzNwaeBV",
    "outputId": "29ec129f-4483-47e7-f458-6d627cb3ff13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After encoding\n",
      "(1511, 753) (1511,)\n",
      "(815, 753) (815,)\n",
      "(997, 753)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding 'Locality'\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "encoder.fit(X_train['Locality'].values.reshape(-1, 1))\n",
    "\n",
    "X_train_locality = encoder.transform(X_train['Locality'].values.reshape(-1, 1))\n",
    "X_cv_locality = encoder.transform(X_cv['Locality'].values.reshape(-1, 1))\n",
    "X_test_locality = encoder.transform(X_test['Locality'].values.reshape(-1, 1))\n",
    "\n",
    "print(\"After encoding\")\n",
    "print(X_train_locality.shape, y_train.shape)\n",
    "print(X_cv_locality.shape, y_cv.shape)\n",
    "print(X_test_locality.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "5uZS46KhdsAC",
    "outputId": "1899e266-6ac1-4c52-bb55-06ef4bd31e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After encoding\n",
      "(1511, 13) (1511,)\n",
      "(815, 13) (815,)\n",
      "(997, 13)\n"
     ]
    }
   ],
   "source": [
    "# 'City'\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "encoder.fit(X_train['City'].values.reshape(-1, 1))\n",
    "\n",
    "X_train_city = encoder.transform(X_train['City'].values.reshape(-1, 1))\n",
    "X_cv_city = encoder.transform(X_cv['City'].values.reshape(-1, 1))\n",
    "X_test_city = encoder.transform(X_test['City'].values.reshape(-1, 1))\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After encoding\")\n",
    "print(X_train_city.shape, y_train.shape)\n",
    "print(X_cv_city.shape, y_cv.shape)\n",
    "print(X_test_city.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Ce2NWyzNduqX",
    "outputId": "3680406a-5749-4600-a68c-d494af7cf09b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After encoding\n",
      "(1511, 9) (1511,)\n",
      "(815, 9) (815,)\n",
      "(997, 9)\n"
     ]
    }
   ],
   "source": [
    "# 'State'\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "encoder.fit(X_train['State'].values.reshape(-1, 1))\n",
    "\n",
    "X_train_state = encoder.transform(X_train['State'].values.reshape(-1, 1))\n",
    "X_cv_state = encoder.transform(X_cv['State'].values.reshape(-1, 1))\n",
    "X_test_state = encoder.transform(X_test['State'].values.reshape(-1, 1))\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After encoding\")\n",
    "print(X_train_state.shape, y_train.shape)\n",
    "print(X_cv_state.shape, y_cv.shape)\n",
    "print(X_test_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "IXUz3U02f6aK",
    "outputId": "006c3f94-9080-41ac-dbbb-fa3c474708c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '100', '11', '11 months', '11 name49', '11 pro', '11 pro max', '12', '128', '128 gb']\n",
      "['xs name229 256 gb', 'xs name229 256gb', 'xs name229 64gb', 'year', 'year apple', 'year old', 'year warranty', 'years', 'years old', 'zu']\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After vectorization\n",
      "(1511, 999) (1511,)\n",
      "(815, 999) (815,)\n",
      "(997, 999)\n"
     ]
    }
   ],
   "source": [
    "# 'preprocessed_model_info' BOW encoding\n",
    "\n",
    "vectorizer = CountVectorizer(min_df = 3, ngram_range = (1,4))\n",
    "vectorizer.fit(X_train['preprocessed_model_info'].values) # fit has to happen only on train data\n",
    "print(vectorizer.get_feature_names()[:10]) \n",
    "print(vectorizer.get_feature_names()[-10:])\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "X_train_model_info_bow = vectorizer.transform(X_train['preprocessed_model_info'].values)\n",
    "X_cv_model_info_bow = vectorizer.transform(X_cv['preprocessed_model_info'].values)\n",
    "X_test_model_info_bow = vectorizer.transform(X_test['preprocessed_model_info'].values)\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After vectorization\")\n",
    "print(X_train_model_info_bow.shape, y_train.shape)\n",
    "print(X_cv_model_info_bow.shape, y_cv.shape)\n",
    "print(X_test_model_info_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "AbmbE5WHgiKN",
    "outputId": "04e15b6e-d08b-4311-daaf-c529b496238b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '100', '11', '11 months', '11 name49', '11 pro', '11 pro max', '12', '128', '128 gb']\n",
      "['xs name229 256 gb', 'xs name229 256gb', 'xs name229 64gb', 'year', 'year apple', 'year old', 'year warranty', 'years', 'years old', 'zu']\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After vectorization\n",
      "(1511, 999) (1511,)\n",
      "(815, 999) (815,)\n",
      "(997, 999)\n"
     ]
    }
   ],
   "source": [
    "# 'preprocessed_model_info' TFIDF encoding\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 3, ngram_range = (1,4))\n",
    "vectorizer.fit(X_train['preprocessed_model_info'].values) # fit has to happen only on train data\n",
    "print(vectorizer.get_feature_names()[:10]) \n",
    "print(vectorizer.get_feature_names()[-10:])\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "X_train_model_info_tfidf = vectorizer.transform(X_train['preprocessed_model_info'].values)\n",
    "X_cv_model_info_tfidf = vectorizer.transform(X_cv['preprocessed_model_info'].values)\n",
    "X_test_model_info_tfidf = vectorizer.transform(X_test['preprocessed_model_info'].values)\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After vectorization\")\n",
    "print(X_train_model_info_tfidf.shape, y_train.shape)\n",
    "print(X_cv_model_info_tfidf.shape, y_cv.shape)\n",
    "print(X_test_model_info_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "f3WJIayWjU-G",
    "outputId": "5540356b-c9d6-4116-d13e-910697537860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '01 call', '01 call 8oo', '01 call 8oo 8oo', '01 call us', '01 call us 8oo', '10', '10 month', '10 months', '100']\n",
      "['year old', 'year used', 'year warranty', 'years', 'years old', 'yes', 'yet', 'yet used', 'yet used interested', 'yet used interested call']\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After vectorization\n",
      "(1511, 1672) (1511,)\n",
      "(815, 1672) (815,)\n",
      "(997, 1672)\n"
     ]
    }
   ],
   "source": [
    "# 'preprocessed_add_desc' BOW encoding\n",
    "\n",
    "vectorizer = CountVectorizer(min_df = 5, ngram_range = (1,4))\n",
    "vectorizer.fit(X_train['preprocessed_add_desc'].values) # fit has to happen only on train data\n",
    "print(vectorizer.get_feature_names()[:10]) \n",
    "print(vectorizer.get_feature_names()[-10:])\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "X_train_add_desc_bow = vectorizer.transform(X_train['preprocessed_add_desc'].values)\n",
    "X_cv_add_desc_bow = vectorizer.transform(X_cv['preprocessed_add_desc'].values)\n",
    "X_test_add_desc_bow = vectorizer.transform(X_test['preprocessed_add_desc'].values)\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After vectorization\")\n",
    "print(X_train_add_desc_bow.shape, y_train.shape)\n",
    "print(X_cv_add_desc_bow.shape, y_cv.shape)\n",
    "print(X_test_add_desc_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "q2oOX0IEjU-r",
    "outputId": "cb06bf20-9b78-4c31-d922-85cbae5b30fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '01 call', '01 call 8oo', '01 call 8oo 8oo', '01 call us', '01 call us 8oo', '10', '10 month', '10 months', '100']\n",
      "['year old', 'year used', 'year warranty', 'years', 'years old', 'yes', 'yet', 'yet used', 'yet used interested', 'yet used interested call']\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After vectorization\n",
      "(1511, 1672) (1511,)\n",
      "(815, 1672) (815,)\n",
      "(997, 1672)\n"
     ]
    }
   ],
   "source": [
    "# 'preprocessed_add_desc' TFIDF encoding\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 5, ngram_range = (1,4))\n",
    "vectorizer.fit(X_train['preprocessed_add_desc'].values) # fit has to happen only on train data\n",
    "print(vectorizer.get_feature_names()[:10]) \n",
    "print(vectorizer.get_feature_names()[-10:])\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "X_train_add_desc_tfidf = vectorizer.transform(X_train['preprocessed_add_desc'].values)\n",
    "X_cv_add_desc_tfidf = vectorizer.transform(X_cv['preprocessed_add_desc'].values)\n",
    "X_test_add_desc_tfidf = vectorizer.transform(X_test['preprocessed_add_desc'].values)\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After vectorization\")\n",
    "print(X_train_add_desc_tfidf.shape, y_train.shape)\n",
    "print(X_cv_add_desc_tfidf.shape, y_cv.shape)\n",
    "print(X_test_add_desc_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4atx4NZkIcc"
   },
   "source": [
    "## Stack all the features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WqgwDog-kMCF",
    "outputId": "5a4969cb-865e-493a-a1ed-9208f1b9ee53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 2697) (1511,)\n",
      "(815, 2697) (815,)\n",
      "(997, 2697)\n"
     ]
    }
   ],
   "source": [
    "# bow encoded text features \n",
    "# drop locality from the list due to very high variation \n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train_bow = hstack((X_train_brand, X_train_city, X_train_state, \n",
    "                      X_train_model_info_bow, X_train_add_desc_bow))\n",
    "\n",
    "X_cv_bow = hstack((X_cv_brand, X_cv_city, X_cv_state, \n",
    "                      X_cv_model_info_bow, X_cv_add_desc_bow))\n",
    "                     \n",
    "X_test_bow = hstack((X_test_brand, X_test_city, X_test_state, \n",
    "                      X_test_model_info_bow, X_test_add_desc_bow))\n",
    "\n",
    "print(X_train_bow.shape, y_train.shape)\n",
    "print(X_cv_bow.shape, y_cv.shape)\n",
    "print(X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "6smClNt6lKl8",
    "outputId": "6a3acd98-0c00-48b3-9962-41a4e4f93782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 2697) (1511,)\n",
      "(815, 2697) (815,)\n",
      "(997, 2697)\n"
     ]
    }
   ],
   "source": [
    "# Tfidf encoded text features \n",
    "# drop locality from the list due to very high variation \n",
    "\n",
    "X_train_tfidf = hstack((X_train_brand, X_train_city, X_train_state, \n",
    "                      X_train_model_info_tfidf, X_train_add_desc_tfidf))\n",
    "\n",
    "X_cv_tfidf = hstack((X_cv_brand, X_cv_city, X_cv_state, \n",
    "                      X_cv_model_info_tfidf, X_cv_add_desc_tfidf))\n",
    "\n",
    "X_test_tfidf = hstack((X_test_brand, X_test_city, X_test_state, \n",
    "                      X_test_model_info_tfidf, X_test_add_desc_tfidf))\n",
    "\n",
    "print(X_train_tfidf.shape, y_train.shape)\n",
    "print(X_cv_tfidf.shape, y_cv.shape)\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9q5J6xGSlcbU"
   },
   "source": [
    "## Training ML Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9jqlsHYo2V2"
   },
   "source": [
    "### 1. SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "j4dHxbgjlePv",
    "outputId": "f328a290-6e49-4f74-dd92-40a7dbbd4675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha : 1e-05 train loss: 0.6814291305941317 cv loss: 1.500500577302415\n",
      "alpha : 0.0001 train loss: 0.6814585607444258 cv loss: 1.4977174104735234\n",
      "alpha : 0.001 train loss: 0.6556896185061114 cv loss: 1.424707822247343\n",
      "alpha : 0.01 train loss: 0.7598247191164191 cv loss: 0.9411936278636065\n",
      "alpha : 0.1 train loss: 0.6320306570258495 cv loss: 0.650844332229113\n",
      "alpha : 1 train loss: 0.6890591154875175 cv loss: 0.7096164066517379\n",
      "alpha : 10 train loss: 0.8232061541620261 cv loss: 0.8040885639776103\n",
      "alpha : 100 train loss: 0.8795602886800882 cv loss: 0.8526524984791323\n",
      "alpha : 1000 train loss: 0.8808725277015917 cv loss: 0.8537126667687314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_log_error \n",
    "\n",
    "for i in [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    sgd = SGDRegressor(alpha = i, random_state = 42)\n",
    "    sgd.fit(X_train_bow, y_train)\n",
    "    y_pred_train = sgd.predict(X_train_bow)\n",
    "    y_pred_cv = sgd.predict(X_cv_bow)\n",
    "\n",
    "    y_pred_train = [0 if m < 0 else m for m in y_pred_train]\n",
    "    y_pred_cv = [0 if n < 0 else n for n in y_pred_cv]\n",
    "\n",
    "    train_loss = np.sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "    cv_loss = np.sqrt(mean_squared_log_error(y_cv, y_pred_cv))\n",
    "    print('alpha :', i, 'train loss:', train_loss, 'cv loss:', cv_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cnlQvmOS_ntP"
   },
   "source": [
    "best alpha = 0.1  Validation RMSLE = 0.651"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jfR6eHKi_sR9"
   },
   "source": [
    "### 2. Linear SVM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "Jp5CYj5LsaV8",
    "outputId": "b68f3ff2-5da6-46f8-e084-4a922daa292f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha : 1e-05 train loss: 0.8453922283191411 cv loss: 0.8233353815221391\n",
      "alpha : 0.0001 train loss: 0.8453914352563741 cv loss: 0.8233347704287839\n",
      "alpha : 0.001 train loss: 0.8453835202305863 cv loss: 0.8233285960959753\n",
      "alpha : 0.01 train loss: 0.8453047137975856 cv loss: 0.8232656965040939\n",
      "alpha : 0.1 train loss: 0.8445173842243038 cv loss: 0.822637655846669\n",
      "alpha : 1 train loss: 0.8367231406453428 cv loss: 0.8165256441253097\n",
      "alpha : 10 train loss: 0.7668793945752427 cv loss: 0.7630296726169268\n",
      "alpha : 100 train loss: 0.5390641554149683 cv loss: 0.6042214022292979\n",
      "alpha : 1000 train loss: 0.41014978175608685 cv loss: 0.7144983695519462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    " \n",
    "\n",
    "for i in [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    svr = SVR(kernel = 'linear', C = i)\n",
    "    svr.fit(X_train_bow, y_train)\n",
    "    y_pred_train = svr.predict(X_train_bow)\n",
    "    y_pred_cv = svr.predict(X_cv_bow)\n",
    "\n",
    "    y_pred_train = [0 if m < 0 else m for m in y_pred_train]\n",
    "    y_pred_cv = [0 if n < 0 else n for n in y_pred_cv]\n",
    "\n",
    "    train_loss = np.sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "    cv_loss = np.sqrt(mean_squared_log_error(y_cv, y_pred_cv))\n",
    "    print('alpha :', i, 'train loss:', train_loss, 'cv loss:', cv_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEF2ohQqA_GN"
   },
   "source": [
    "best alpha = 100     Validation RMSLE = 0.604"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PNNO6DRzDbNT"
   },
   "source": [
    "### 3. XGB Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgPo3kMaGmDm"
   },
   "source": [
    "> Note: Taking into consideration the time left to complete hackathon and current availibility of computational resources, I decided to go for manual hyperparameter tuning instead of GridSearchCV/RandomizedSearchCV as we normally do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "JaiKNoy7DbOQ",
    "outputId": "d45d7f05-df00-4954-bf9e-7cc2a4e931a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 10 train loss: 0.698583207432532 cv loss: 0.7080222810021619\n",
      "n_estimators: 50 train loss: 0.5797496814082188 cv loss: 0.6011568418210969\n",
      "n_estimators: 100 train loss: 0.5271889510250836 cv loss: 0.5731493803574109\n",
      "n_estimators: 150 train loss: 0.4939911927973297 cv loss: 0.5607844060361328\n",
      "n_estimators: 250 train loss: 0.4522854888169123 cv loss: 0.5524689655780366\n",
      "n_estimators: 500 train loss: 0.391517039729832 cv loss: 0.5468075085169569\n",
      "n_estimators: 700 train loss: 0.3602038388497608 cv loss: 0.619415959593049\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning the number of estimators \n",
    "from xgboost.sklearn import XGBRegressor\n",
    " \n",
    "for i in [10, 50, 100, 150, 250, 500, 700]:\n",
    "    xgb = XGBRegressor(objective ='reg:squarederror', n_estimators = i, random_state = 42)\n",
    "    xgb.fit(X_train_bow, y_train)\n",
    "    y_pred_train = xgb.predict(X_train_bow)\n",
    "    y_pred_cv = xgb.predict(X_cv_bow)\n",
    "\n",
    "    y_pred_train = [0 if m < 0 else m for m in y_pred_train]\n",
    "    y_pred_cv = [0 if n < 0 else n for n in y_pred_cv]\n",
    "\n",
    "    train_loss = np.sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "    cv_loss = np.sqrt(mean_squared_log_error(y_cv, y_pred_cv))\n",
    "    print('n_estimators:', i,'train loss:', train_loss, 'cv loss:', cv_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LxRMbbomCkux"
   },
   "source": [
    "n_estimators = 500 Validation loss = 0.547"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q8yrONhYC0kL"
   },
   "source": [
    "Next, with n_estimators = 500 we fine-tune the max_depth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "p4S0HrLWtiOF",
    "outputId": "5634bcb9-347e-44cd-e45d-ce10b6a7caaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 2 train loss: 0.45320159362942775 cv loss: 0.5591004216423104\n",
      "max_depth: 3 train loss: 0.391517039729832 cv loss: 0.5468075085169569\n",
      "max_depth: 5 train loss: 0.30766295348246187 cv loss: 0.6196092133291659\n",
      "max_depth: 7 train loss: 0.2471809523596218 cv loss: 0.6313522162930615\n"
     ]
    }
   ],
   "source": [
    "# fine tuning max-depth \n",
    "\n",
    "for i in [2, 3, 5, 7]:\n",
    "    xgb = XGBRegressor(n_estimators = 500, objective ='reg:squarederror', max_depth = i, random_state = 42)\n",
    "    xgb.fit(X_train_bow, y_train)\n",
    "    y_pred_train = xgb.predict(X_train_bow)\n",
    "    y_pred_cv = xgb.predict(X_cv_bow)\n",
    "\n",
    "    y_pred_train = [0 if m < 0 else m for m in y_pred_train]\n",
    "    y_pred_cv = [0 if n < 0 else n for n in y_pred_cv]\n",
    "\n",
    "    train_loss = np.sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "    cv_loss = np.sqrt(mean_squared_log_error(y_cv, y_pred_cv))\n",
    "    print('max_depth:', i,'train loss:', train_loss, 'cv loss:', cv_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5j2UqwXEDIPk"
   },
   "source": [
    "Thus, optimal max_depth = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NCZWLxdUIuuE"
   },
   "source": [
    "Next, with n_estimator = 500 and max_depth = 3, we fine-tune 'colsample_bytree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Wi-ZGy2fszff",
    "outputId": "4851933f-9803-4319-b143-ebccbb8fdd03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_sample_by_tree: 0.3 train loss: 0.5573379952933728 cv loss: 0.613271276901688\n",
      "col_sample_by_tree: 0.4 train loss: 0.4579210376138219 cv loss: 0.5519761605544066\n",
      "col_sample_by_tree: 0.6 train loss: 0.456568406143203 cv loss: 0.5497182364692842\n",
      "col_sample_by_tree: 0.8 train loss: 0.45342562215978754 cv loss: 0.5486401142401411\n",
      "col_sample_by_tree: 1 train loss: 0.4522854888169123 cv loss: 0.5524689655780366\n"
     ]
    }
   ],
   "source": [
    "# fine tuning colsample_bytree\n",
    "\n",
    "for i in [0.3, 0.4, 0.6, 0.8, 1]:\n",
    "    xgb = XGBRegressor(colsample_bytree = i, n_estimators = 250, objective ='reg:squarederror', max_depth = 3, random_state = 42)\n",
    "    xgb.fit(X_train_bow, y_train)\n",
    "    y_pred_train = xgb.predict(X_train_bow)\n",
    "    y_pred_cv = xgb.predict(X_cv_bow)\n",
    "\n",
    "    y_pred_train = [0 if m < 0 else m for m in y_pred_train]\n",
    "    y_pred_cv = [0 if n < 0 else n for n in y_pred_cv]\n",
    "\n",
    "    train_loss = np.sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "    cv_loss = np.sqrt(mean_squared_log_error(y_cv, y_pred_cv))\n",
    "    print('col_sample_by_tree:', i,'train loss:', train_loss, 'cv loss:', cv_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yePm-7LkDdr-"
   },
   "source": [
    "colsample_by_tree: 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5peFW8NDjzC"
   },
   "source": [
    "Check again for n_estimators using colsample_bytree = 0.8, max_depth = 3 to see if we get better performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "gDVx7uMK8DRZ",
    "outputId": "bd8b81d8-52ee-4c28-b4a9-14e5fb397bc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimator: 10 train loss: 0.6839034145304946 cv loss: 0.6860601178529161\n",
      "n_estimator: 50 train loss: 0.5808605839541485 cv loss: 0.5999064585058881\n",
      "n_estimator: 100 train loss: 0.5291280072897985 cv loss: 0.5710494904432875\n",
      "n_estimator: 150 train loss: 0.49768520249697024 cv loss: 0.5612920783880736\n",
      "n_estimator: 250 train loss: 0.4579210376138219 cv loss: 0.5519761605544066\n",
      "n_estimator: 500 train loss: 0.40217276580720845 cv loss: 0.6066409769472102\n",
      "n_estimator: 700 train loss: 0.3740074831951074 cv loss: 0.6165513219908468\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    " \n",
    "for i in [10, 50, 100, 150, 250, 500, 700]:\n",
    "    xgb = XGBRegressor(colsample_bytree = 0.4,  n_estimators = i, objective ='reg:squarederror', max_depth = 3, random_state = 42)\n",
    "    xgb.fit(X_train_bow, y_train)\n",
    "    y_pred_train = xgb.predict(X_train_bow)\n",
    "    y_pred_cv = xgb.predict(X_cv_bow)\n",
    "\n",
    "    y_pred_train = [0 if m < 0 else m for m in y_pred_train]\n",
    "    y_pred_cv = [0 if n < 0 else n for n in y_pred_cv]\n",
    "\n",
    "    train_loss = np.sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "    cv_loss = np.sqrt(mean_squared_log_error(y_cv, y_pred_cv))\n",
    "    print('n_estimator:', i,'train loss:', train_loss, 'cv loss:', cv_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rOXtvgcEEChI"
   },
   "source": [
    "Thus, n_estimators = 250 gives best score on validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k6AoEB35FzXX"
   },
   "source": [
    "with n_estimators as 250, colsample_bytree = 0.8, vary max depth and check for the performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "39UftBZmFun6",
    "outputId": "2994ebc8-e710-472d-ac89-be932cb1c999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 2 train loss: 0.5019919826754776 cv loss: 0.5627084186481026\n",
      "max_depth: 3 train loss: 0.45342562215978754 cv loss: 0.5486401142401411\n",
      "max_depth: 5 train loss: 0.3780682012880054 cv loss: 0.5429486756748865\n",
      "max_depth: 7 train loss: 0.3273621713892148 cv loss: 0.5523136647475682\n"
     ]
    }
   ],
   "source": [
    "# again tuning max-depth using n_estimators = 250 and colsample_bytree = 0.8\n",
    " \n",
    "for i in [2, 3, 5, 7]:\n",
    "    xgb = XGBRegressor(colsample_bytree = 0.8,  n_estimators = 250, objective ='reg:squarederror', max_depth = i, random_state = 42)\n",
    "    xgb.fit(X_train_bow, y_train)\n",
    "    y_pred_train = xgb.predict(X_train_bow)\n",
    "    y_pred_cv = xgb.predict(X_cv_bow)\n",
    "\n",
    "    y_pred_train = [0 if m < 0 else m for m in y_pred_train]\n",
    "    y_pred_cv = [0 if n < 0 else n for n in y_pred_cv]\n",
    "\n",
    "    train_loss = np.sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "    cv_loss = np.sqrt(mean_squared_log_error(y_cv, y_pred_cv))\n",
    "    print('max_depth:', i,'train loss:', train_loss, 'cv loss:', cv_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iz9VsbooemDg"
   },
   "source": [
    "Thus, now we select max_depth = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SnUsmtUDezYm"
   },
   "source": [
    "Next, with the above found hyperparameters, check the performance with Tf-IDF encoded text features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D2p2KbSwefUN",
    "outputId": "1f416ca6-c64e-4e55-ee51-5d1a2de6b1c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.36958254468413926 cv loss: 0.5552682965937445\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(colsample_bytree = 0.8,  n_estimators = 250, objective ='reg:squarederror', max_depth = 5, random_state = 42)\n",
    "xgb.fit(X_train_tfidf, y_train)\n",
    "y_pred_train = xgb.predict(X_train_tfidf)\n",
    "y_pred_cv = xgb.predict(X_cv_tfidf)\n",
    "\n",
    "y_pred_train = [0 if m < 0 else m for m in y_pred_train]\n",
    "y_pred_cv = [0 if n < 0 else n for n in y_pred_cv]\n",
    "\n",
    "train_loss = np.sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "cv_loss = np.sqrt(mean_squared_log_error(y_cv, y_pred_cv))\n",
    "print('train loss:', train_loss, 'cv loss:', cv_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1kDYaNJJGad_"
   },
   "source": [
    "Final optimal hyperparameters we got upon fine-tuning:\n",
    "\n",
    "* n_estimators = 250\n",
    "* max_depth = 5\n",
    "* colsample_bytree = 0.8\n",
    "* subsample = 1 (default)\n",
    "\n",
    "Validation RMSLE = 0.543\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZKXi6B87lkEL"
   },
   "source": [
    "Now, we'll train the model on the entire Train data to make the predictions on the Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_DDbBQM2nqFD"
   },
   "source": [
    "### Reading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rh6VT_w_Mq77"
   },
   "outputs": [],
   "source": [
    "# reading data from google drive \n",
    "\n",
    "mypath = '/content/gdrive/My Drive/MachineHack/Used Electronics Price Prediction/'\n",
    "train_data = pd.read_csv(mypath + 'Train.csv')\n",
    "test_data = pd.read_csv(mypath + 'Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "x9DYBQM_Mq8P",
    "outputId": "96251eda-0579-48d3-9bbc-1428418d19bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2326, 6) (2326,)\n",
      "(997, 6)\n"
     ]
    }
   ],
   "source": [
    "y_train = train_data['Price']\n",
    "X_train = train_data.drop('Price', axis = 1)\n",
    "X_test = test_data\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRy7nQK0nt1o"
   },
   "source": [
    "### Data cleaning and Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o_o5uXJeNOTF",
    "outputId": "5057bc42-fdd4-475e-83a8-44d9fe8e79a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2326/2326 [00:33<00:00, 69.93it/s]\n"
     ]
    }
   ],
   "source": [
    "spell = Speller(lang='en')\n",
    "\n",
    "preprocessed_model_info = []\n",
    "\n",
    "for sent in tqdm(X_train['Model_Info'].values):\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    sent = spell_check(sent)\n",
    "    preprocessed_model_info.append(sent.strip())\n",
    "\n",
    "X_train['preprocessed_model_info'] = preprocessed_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mt3OUvINNOTf"
   },
   "outputs": [],
   "source": [
    "X_train['preprocessed_model_info'] = X_train['preprocessed_model_info'].str.replace('phone', 'name0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sYiwsEgiNOTr",
    "outputId": "edbdf7df-10bc-4f4a-830e-fce13a6b6476"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 997/997 [00:05<00:00, 175.13it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_model_info = []\n",
    "\n",
    "for sent in tqdm(X_test['Model_Info'].values):\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    sent = spell_check(sent)\n",
    "    preprocessed_model_info.append(sent.strip())\n",
    "\n",
    "X_test['preprocessed_model_info'] = preprocessed_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oaR-0F7NOT0"
   },
   "outputs": [],
   "source": [
    "X_test['preprocessed_model_info'] = X_test['preprocessed_model_info'].str.replace('phone', 'name0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "89Mm17qlNOT9",
    "outputId": "a99e1acc-d650-47cb-b4a1-d9352a3326e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2326/2326 [02:57<00:00, 13.09it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_add_desc = []\n",
    "\n",
    "for sent in tqdm(X_train['Additional_Description'].values):\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    sent = \" \".join(filter(lambda x:x[:5]!='10100', sent.split()))\n",
    "    sent = spell_check(sent)\n",
    "    preprocessed_add_desc.append(sent.strip())\n",
    "\n",
    "X_train['preprocessed_add_desc'] = preprocessed_add_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-JwjElhnNOUM",
    "outputId": "aa8847d4-ff28-40c7-e182-5faa37431bc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 997/997 [00:59<00:00, 16.62it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_add_desc = []\n",
    "\n",
    "for sent in tqdm(X_test['Additional_Description'].values):\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    sent = \" \".join(filter(lambda x:x[:5]!='10100', sent.split()))\n",
    "    sent = spell_check(sent)\n",
    "    preprocessed_add_desc.append(sent.strip())\n",
    "\n",
    "X_test['preprocessed_add_desc'] = preprocessed_add_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "yVqRNnhRN9rV",
    "outputId": "fb29f3a8-27aa-4433-a4b5-69a6cc7c2562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After encoding\n",
      "(2326, 4) (2326,)\n",
      "(997, 4)\n"
     ]
    }
   ],
   "source": [
    "# brand\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(X_train['Brand'].values.reshape(-1, 1))\n",
    "\n",
    "X_train_brand = encoder.transform(X_train['Brand'].values.reshape(-1, 1))\n",
    "X_test_brand = encoder.transform(X_test['Brand'].values.reshape(-1, 1))\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After encoding\")\n",
    "print(X_train_brand.shape, y_train.shape)\n",
    "print(X_test_brand.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "3kx3z6rJN9rl",
    "outputId": "c183718c-832b-44d0-a625-0ca013f0f800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After encoding\n",
      "(2326, 970) (2326,)\n",
      "(997, 970)\n"
     ]
    }
   ],
   "source": [
    "# locality\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "encoder.fit(X_train['Locality'].values.reshape(-1, 1))\n",
    "\n",
    "X_train_locality = encoder.transform(X_train['Locality'].values.reshape(-1, 1))\n",
    "X_test_locality = encoder.transform(X_test['Locality'].values.reshape(-1, 1))\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After encoding\")\n",
    "print(X_train_locality.shape, y_train.shape)\n",
    "print(X_test_locality.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "cJ_EVeidN9r0",
    "outputId": "46cc7f31-e546-4700-d8b2-b72a27b02959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After encoding\n",
      "(2326, 16) (2326,)\n",
      "(997, 16)\n"
     ]
    }
   ],
   "source": [
    "# City\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "encoder.fit(X_train['City'].values.reshape(-1, 1))\n",
    "\n",
    "X_train_city = encoder.transform(X_train['City'].values.reshape(-1, 1))\n",
    "X_test_city = encoder.transform(X_test['City'].values.reshape(-1, 1))\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After encoding\")\n",
    "print(X_train_city.shape, y_train.shape)\n",
    "print(X_test_city.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-wDhB1ffN9r_",
    "outputId": "e5c561d3-eaa4-4560-e7c8-df54e81eb919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After encoding\n",
      "(2326, 9) (2326,)\n",
      "(997, 9)\n"
     ]
    }
   ],
   "source": [
    "# State\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "encoder.fit(X_train['State'].values.reshape(-1, 1))\n",
    "\n",
    "X_train_state = encoder.transform(X_train['State'].values.reshape(-1, 1))\n",
    "X_test_state = encoder.transform(X_test['State'].values.reshape(-1, 1))\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After encoding\")\n",
    "print(X_train_state.shape, y_train.shape)\n",
    "print(X_test_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "B1_lTZgsN9sI",
    "outputId": "d1c7a5f6-feb7-4d21-f3b6-d11e213cb7c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '10 months', '100', '100 condition', '11', '11 64', '11 64 gb', '11 64gb', '11 months', '11 name49']\n",
      "['year apple', 'year name243', 'year name87', 'year old', 'year warranty', 'years', 'years old', 'z2', 'z2 plus', 'zu']\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After vectorization\n",
      "(2326, 1544) (2326,)\n",
      "(997, 1544)\n"
     ]
    }
   ],
   "source": [
    "# preprocessed_model_info BOW encoding\n",
    "\n",
    "vectorizer = CountVectorizer(min_df = 3, ngram_range = (1,4))\n",
    "vectorizer.fit(X_train['preprocessed_model_info'].values) # fit has to happen only on train data\n",
    "print(vectorizer.get_feature_names()[:10]) \n",
    "print(vectorizer.get_feature_names()[-10:])\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "X_train_model_info_bow = vectorizer.transform(X_train['preprocessed_model_info'].values)\n",
    "X_test_model_info_bow = vectorizer.transform(X_test['preprocessed_model_info'].values)\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After vectorization\")\n",
    "print(X_train_model_info_bow.shape, y_train.shape)\n",
    "print(X_test_model_info_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "bXYmOVOcN9sd",
    "outputId": "3b6cb5ae-d2de-4deb-9580-9d934ac94413"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '01 call', '01 call 8oo', '01 call 8oo 8oo', '01 call us', '01 call us 8oo', '10', '10 10', '10 10 100', '10 10 100 fixed']\n",
      "['you', 'yr', 'yr old', 'yrs', 'ysame', 'ysame day', 'ysame day week', 'ysame day week return', 'zero', 'zoom']\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After vectorization\n",
      "(2326, 5414) (2326,)\n",
      "(997, 5414)\n"
     ]
    }
   ],
   "source": [
    "# preprocessed_add_desc BOW encoding\n",
    "\n",
    "vectorizer = CountVectorizer(min_df = 3, ngram_range = (1, 4))\n",
    "vectorizer.fit(X_train['preprocessed_add_desc'].values) # fit has to happen only on train data\n",
    "print(vectorizer.get_feature_names()[:10]) \n",
    "print(vectorizer.get_feature_names()[-10:])\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "X_train_add_desc_bow = vectorizer.transform(X_train['preprocessed_add_desc'].values)\n",
    "X_test_add_desc_bow = vectorizer.transform(X_test['preprocessed_add_desc'].values)\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After vectorization\")\n",
    "print(X_train_add_desc_bow.shape, y_train.shape)\n",
    "print(X_test_add_desc_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "4Z6ROE0VSVHD",
    "outputId": "71a569fc-8e40-46e0-ea76-4e9874e55da2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '10 months', '100', '100 condition', '11', '11 64', '11 64 gb', '11 64gb', '11 months', '11 name49']\n",
      "['year apple', 'year name243', 'year name87', 'year old', 'year warranty', 'years', 'years old', 'z2', 'z2 plus', 'zu']\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After vectorization\n",
      "(2326, 1544) (2326,)\n",
      "(997, 1544)\n"
     ]
    }
   ],
   "source": [
    "# preprocessed_model_info TF-IDF encoding\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 3, ngram_range = (1, 4))\n",
    "vectorizer.fit(X_train['preprocessed_model_info'].values) # fit has to happen only on train data\n",
    "print(vectorizer.get_feature_names()[:10]) \n",
    "print(vectorizer.get_feature_names()[-10:])\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "X_train_model_info_tfidf = vectorizer.transform(X_train['preprocessed_model_info'].values)\n",
    "X_test_model_info_tfidf = vectorizer.transform(X_test['preprocessed_model_info'].values)\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After vectorization\")\n",
    "print(X_train_model_info_tfidf.shape, y_train.shape)\n",
    "print(X_test_model_info_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "7JmYAEfKSVHr",
    "outputId": "1e906947-a3b9-497b-99da-f18bdc66c567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '01 call', '01 call 8oo', '01 call 8oo 8oo', '01 call us', '01 call us 8oo', '10', '10 10', '10 10 100', '10 10 100 fixed']\n",
      "['you', 'yr', 'yr old', 'yrs', 'ysame', 'ysame day', 'ysame day week', 'ysame day week return', 'zero', 'zoom']\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "After vectorization\n",
      "(2326, 5414) (2326,)\n",
      "(997, 5414)\n"
     ]
    }
   ],
   "source": [
    "# preprocessed_add_desc TF-IDF encoding\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 3, ngram_range = (1,4))\n",
    "vectorizer.fit(X_train['preprocessed_add_desc'].values) # fit has to happen only on train data\n",
    "print(vectorizer.get_feature_names()[:10]) \n",
    "print(vectorizer.get_feature_names()[-10:])\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "X_train_add_desc_tfidf = vectorizer.transform(X_train['preprocessed_add_desc'].values)\n",
    "X_test_add_desc_tfidf = vectorizer.transform(X_test['preprocessed_add_desc'].values)\n",
    "\n",
    "print('- '*50)\n",
    "print(\"After vectorization\")\n",
    "print(X_train_add_desc_tfidf.shape, y_train.shape)\n",
    "print(X_test_add_desc_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwbU9tX6ni0m"
   },
   "source": [
    "### Stacking the above perprocessed model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "JqUNoePPN9sz",
    "outputId": "a8a135da-4299-481c-cbfe-0275f4e2eaad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2326, 7957) (2326,)\n",
      "(997, 7957)\n"
     ]
    }
   ],
   "source": [
    "# set 1: with BOW encoded text features \n",
    "\n",
    "X_train_bow = hstack((X_train_brand, X_train_locality, X_train_city, X_train_state, \n",
    "                      X_train_model_info_bow, X_train_add_desc_bow))\n",
    "                     \n",
    "X_test_bow = hstack((X_test_brand, X_test_locality, X_test_city, X_test_state, \n",
    "                      X_test_model_info_bow, X_test_add_desc_bow))\n",
    "\n",
    "print(X_train_bow.shape, y_train.shape)\n",
    "print(X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rvaU6WbOSyOP",
    "outputId": "4fbd3251-c30b-4f8f-826a-f40881752936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2326, 7957) (2326,)\n",
      "(997, 7957)\n"
     ]
    }
   ],
   "source": [
    "# set 2: with TFIDF encoded text features \n",
    "\n",
    "X_train_tfidf = hstack((X_train_brand, X_train_locality, X_train_city, X_train_state, \n",
    "                      X_train_model_info_tfidf, X_train_add_desc_tfidf))\n",
    "                     \n",
    "X_test_tfidf = hstack((X_test_brand, X_test_locality, X_test_city, X_test_state, \n",
    "                      X_test_model_info_tfidf, X_test_add_desc_tfidf))\n",
    "\n",
    "print(X_train_tfidf.shape, y_train.shape)\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TaSkcmgOnD69"
   },
   "source": [
    "### Model 1: Linear Support Vector Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n9Timmk1TpL-"
   },
   "outputs": [],
   "source": [
    "for i in [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    svr = SVR(kernel = 'linear', C = i)\n",
    "    svr.fit(X_train_bow, y_train)\n",
    "    y_pred_train = svr.predict(X_train_bow)\n",
    "    y_pred_cv = svr.predict(X_cv_bow)\n",
    "\n",
    "    y_pred_train = [0 if m < 0 else m for m in y_pred_train]\n",
    "    y_pred_cv = [0 if n < 0 else n for n in y_pred_cv]\n",
    "\n",
    "    train_loss = np.sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "    cv_loss = np.sqrt(mean_squared_log_error(y_cv, y_pred_cv))\n",
    "    print('alpha :', i, 'train loss:', train_loss, 'cv loss:', cv_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dvua3FDrTsDD",
    "outputId": "5eda59f2-fd53-4cac-f77a-e9b7927127d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5404383896436994\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(kernel = 'linear', C = 100)\n",
    "svr.fit(X_train_tfidf, y_train)\n",
    "y_pred_train = xgb.predict(X_train_tfidf)\n",
    "y_pred_test = xgb.predict(X_test_tfidf)\n",
    "\n",
    "y_pred_train = [0 if m < 0 else m for m in y_pred_train]\n",
    "y_pred_test = [0 if n < 0 else n for n in y_pred_test]\n",
    "\n",
    "train_loss = np.sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "print('train loss:', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "BmT5MilFTsDM",
    "outputId": "b9c53873-a7f1-4b86-ce0c-38e30bb4d732"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21468.050781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20871.742188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20871.742188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27101.177734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13008.355469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Price\n",
       "0  21468.050781\n",
       "1  20871.742188\n",
       "2  20871.742188\n",
       "3  27101.177734\n",
       "4  13008.355469"
      ]
     },
     "execution_count": 148,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_df1 = pd.DataFrame(data = y_pred_test, columns = ['Price'])\n",
    "svr_df1 .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDc9qIhQTsDR"
   },
   "outputs": [],
   "source": [
    "# SUBMISSION 1\n",
    "\n",
    "svr_df1.to_excel(mypath + 'svr_1.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EFPWmVGFm1e4"
   },
   "source": [
    "### Model 2: XGBoost Regressor with BOW encoded features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "20wYG7BvPSq9",
    "outputId": "9b04553a-c1cd-41ff-a8a6-4be38632ebb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4221324284214125\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning model: ensemble model XGBoost regressor with best hyperparameter found above \n",
    "from xgboost.sklearn import XGBRegressor\n",
    " \n",
    "xgb = XGBRegressor(colsample_bytree = 0.8, n_estimators = 250, objective ='reg:squarederror', max_depth = 5, random_state = 42)\n",
    "xgb.fit(X_train_bow, y_train)\n",
    "y_pred_train = xgb.predict(X_train_bow)\n",
    "y_pred_test = xgb.predict(X_test_bow)\n",
    "\n",
    "y_pred_train = [0 if m < 0 else m for m in y_pred_train]\n",
    "y_pred_test = [0 if n < 0 else n for n in y_pred_test]\n",
    "\n",
    "train_loss = np.sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "print('train loss:', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "nnrt062TP0Q6",
    "outputId": "ff9116a1-f176-498c-df59-4af4316bf71b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19834.861328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17818.236328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23766.871094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25269.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9485.232422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Price\n",
       "0  19834.861328\n",
       "1  17818.236328\n",
       "2  23766.871094\n",
       "3  25269.828125\n",
       "4   9485.232422"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_df = pd.DataFrame(data = y_pred_test, columns = ['Price'])\n",
    "xgb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98Yx94zAP3S2"
   },
   "outputs": [],
   "source": [
    "# SUBMISSION 2\n",
    "\n",
    "xgb_df.to_excel(mypath + 'xgb_tuned_1.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0-v_auXm7C-"
   },
   "source": [
    "### Model 3: XGBoost Regressor with TF-IDF encode features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6tZ-P8ihS93F",
    "outputId": "2aee113e-0ce4-4baf-a868-3b62e9135722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4054309571299996\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    " \n",
    "xgb = XGBRegressor(colsample_bytree = 0.8, n_estimators = 250, objective ='reg:squarederror', max_depth = 5, random_state = 42)\n",
    "xgb.fit(X_train_tfidf, y_train)\n",
    "y_pred_train = xgb.predict(X_train_tfidf)\n",
    "y_pred_test = xgb.predict(X_test_tfidf)\n",
    "\n",
    "y_pred_train = [0 if m < 0 else m for m in y_pred_train]\n",
    "y_pred_test = [0 if n < 0 else n for n in y_pred_test]\n",
    "\n",
    "train_loss = np.sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "print('train loss:', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "AGllFS9_S93X",
    "outputId": "f4cb7d39-0240-4337-ecc4-f004ad3abc31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20688.111328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17241.326172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17697.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27364.873047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8990.277344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Price\n",
       "0  20688.111328\n",
       "1  17241.326172\n",
       "2  17697.835938\n",
       "3  27364.873047\n",
       "4   8990.277344"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_df2 = pd.DataFrame(data = y_pred_test, columns = ['Price'])\n",
    "xgb_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCN1s7PzS93q"
   },
   "outputs": [],
   "source": [
    "# SUBMISSION 3\n",
    "xgb_df2.to_excel(mypath + 'xgb_tuned_tfidf.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MachineHack_Used_electronics_price_prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
